# Practice-3.1-3.5

## 1. Сортировка выбором
АНАЛИЗ РАБОТЫ АЛГОРИТМА:

Принцип работы:
Сортировка выбором работает по принципу разделения массива на две части:

· Отсортированная часть - в начале массива (изначально пустая)
· Неотсортированная часть - оставшаяся часть массива

Пошаговый процесс выполнения на примере массива [64, 25, 12, 22, 11]:

Итерация 1 (i = 0):

· Ищем минимальный элемент во всем массиве: min = 11 (индекс 4)
· Меняем местами arr[0] и arr[4]: [11, 25, 12, 22, 64]
· Теперь отсортированная часть: [11], неотсортированная: [25, 12, 22, 64]

Итерация 2 (i = 1):

· Ищем минимальный в неотсортированной части [25, 12, 22, 64]: min = 12 (индекс 2)
· Меняем местами arr[1] и arr[2]: [11, 12, 25, 22, 64]
· Отсортированная часть: [11, 12], неотсортированная: [25, 22, 64]

Итерация 3 (i = 2):

· Ищем минимальный в [25, 22, 64]: min = 22 (индекс 3)
· Меняем местами arr[2] и arr[3]: [11, 12, 22, 25, 64]
· Отсортированная часть: [11, 12, 22], неотсортированная: [25, 64]

Итерация 4 (i = 3):

· Ищем минимальный в [25, 64]: min = 25 (уже на месте)
· Массив остается: [11, 12, 22, 25, 64]

Результат: [11, 12, 22, 25, 64]

ОЦЕНКА ТРУДОЁМКОСТИ (НОТАЦИЯ BIG O):

Временная сложность:

1. Лучший случай: O(n²)
   · Даже если массив уже отсортирован, алгоритм все равно выполнит полные проходы
   · Всегда выполняется двойной цикл
2. Средний случай: O(n²)
   · В среднем требуется сравнить каждый элемент с половиной оставшихся элементов
3. Худший случай: O(n²)
   · Массив отсортирован в обратном порядке
   · Все равно выполняется полное количество сравнений

Математическое обоснование:
Количество сравнений = (n-1) + (n-2) + ... + 1 = n(n-1)/2 ∈ O(n²)

Пространственная сложность: O(1)

· Алгоритм сортирует массив "на месте" (in-place)
· Используется только несколько дополнительных переменных (i, j, minIndex)
· Не требует дополнительной памяти, пропорциональной размеру входных данных

Ключевые характеристики:

· Неустойчивая сортировка - может менять относительный порядок одинаковых элементов
· Медленный алгоритм для больших массивов из-за квадратичной сложности
· Простой в реализации и понимании
· Эффективен для небольших массивов или когда стоимость обмена высока

## 2. Сортировка обменом
ПОДРОБНЫЙ АНАЛИЗ РАБОТЫ АЛГОРИТМА:

Принцип работы:
Пузырьковая сортировка работает по принципу многократного прохода по массиву и сравнения соседних элементов. "Тяжелые" элементы постепенно "всплывают" в конец массива, как пузырьки в воде.

Пошаговый процесс выполнения на примере массива [5, 3, 8, 4, 2]:

Первый проход (i = 0):

· Сравниваем 5 и 3: 5 > 3 → меняем: [3, 5, 8, 4, 2]
· Сравниваем 5 и 8: 5 < 8 → не меняем: [3, 5, 8, 4, 2]
· Сравниваем 8 и 4: 8 > 4 → меняем: [3, 5, 4, 8, 2]
· Сравниваем 8 и 2: 8 > 2 → меняем: [3, 5, 4, 2, 8]
· Самый большой элемент (8) "всплыл" в конец

Второй проход (i = 1):

· Сравниваем 3 и 5: 3 < 5 → не меняем: [3, 5, 4, 2, 8]
· Сравниваем 5 и 4: 5 > 4 → меняем: [3, 4, 5, 2, 8]
· Сравниваем 5 и 2: 5 > 2 → меняем: [3, 4, 2, 5, 8]
· Второй по величине элемент (5) на своем месте

Третий проход (i = 2):

· Сравниваем 3 и 4: 3 < 4 → не меняем: [3, 4, 2, 5, 8]
· Сравниваем 4 и 2: 4 > 2 → меняем: [3, 2, 4, 5, 8]
· Третий элемент (4) на месте

Четвертый проход (i = 3):

· Сравниваем 3 и 2: 3 > 2 → меняем: [2, 3, 4, 5, 8]
· Массив полностью отсортирован

ОЦЕНКА ТРУДОЁМКОСТИ (НОТАЦИЯ BIG O):

Временная сложность:

1. Худший случай: O(n²)
   · Массив отсортирован в обратном порядке
   · Количество сравнений: (n-1) + (n-2) + ... + 1 = n(n-1)/2 ∈ O(n²)
   · Количество обменов: такое же как сравнений
2. Средний случай: O(n²)
   · В среднем требуется n²/2 сравнений и n²/4 обменов
3. Лучший случай (обычная версия): O(n²)
   · Даже для уже отсортированного массива выполняются все проходы
4. Лучший случай (оптимизированная версия): O(n)
   · Для уже отсортированного массива достаточно одного прохода
   · Флаг swapped позволяет досрочно завершить сортировку

Пространственная сложность: O(1)

· Алгоритм сортирует "на месте"
· Используется только несколько дополнительных переменных (i, j, temp/swapped)
· Не требует дополнительной памяти, пропорциональной размеру входных данных

Ключевые характеристики:

· Устойчивая сортировка - сохраняет относительный порядок одинаковых элементов
· Очень медленный алгоритм для больших массивов
· Простой в реализации и понимании
· Хорош для обучения основам алгоритмов сортировки
· Эффективен только для очень маленьких массивов или почти отсортированных данных

Сравнение с сортировкой выбором:

· Пузырьковая: Много обменов, мало сравнений (в худшем случае n² обменов)
· Выбором: Мало обменов (ровно n-1), много сравнений (n² сравнений)
· Выбором обычно быстрее на практике из-за меньшего количества обменов

Практическое применение:
Используется в основном в образовательных целях. В реальных приложениях заменяется более эффективными алгоритмами (быстрая сортировка, сортировка слиянием и др.).

## 3. Сортировка вставками

ПОДРОБНЫЙ АНАЛИЗ РАБОТЫ АЛГОРИТМА:

Принцип работы:
Сортировка вставками работает по принципу обработки карт в руке. Мы начинаем с пустой "руки" (отсортированной части) и постепенно "вставляем" каждую новую карту в правильную позицию.

Пошаговый процесс выполнения на примере массива [12, 11, 13, 5, 6]:

Начальное состояние: Отсортированная часть: [12], Неотсортированная: [11, 13, 5, 6]

Итерация 1 (i = 1):

· Key = 11
· Сравниваем с 12: 11 < 12 → сдвигаем 12 вправо: [12, 12, 13, 5, 6]
· Дошли до начала → вставляем 11: [11, 12, 13, 5, 6]

Итерация 2 (i = 2):

· Key = 13
· Сравниваем с 12: 13 > 12 → вставляем сразу: [11, 12, 13, 5, 6]

Итерация 3 (i = 3):

· Key = 5
· Сравниваем с 13: 5 < 13 → сдвигаем 13: [11, 12, 13, 13, 6]
· Сравниваем с 12: 5 < 12 → сдвигаем 12: [11, 12, 12, 13, 6]
· Сравниваем с 11: 5 < 11 → сдвигаем 11: [11, 11, 12, 13, 6]
· Дошли до начала → вставляем 5: [5, 11, 12, 13, 6]

Итерация 4 (i = 4):

· Key = 6
· Сравниваем с 13: 6 < 13 → сдвигаем 13: [5, 11, 12, 13, 13]
· Сравниваем с 12: 6 < 12 → сдвигаем 12: [5, 11, 12, 12, 13]
· Сравниваем с 11: 6 < 11 → сдвигаем 11: [5, 11, 11, 12, 13]
· Сравниваем с 5: 6 > 5 → вставляем 6: [5, 6, 11, 12, 13]

Результат: [5, 6, 11, 12, 13]

ОЦЕНКА ТРУДОЁМКОСТИ (НОТАЦИЯ BIG O):

Временная сложность:

1. Худший случай: O(n²)
   · Массив отсортирован в обратном порядке
   · Каждый новый элемент нужно сдвигать через всю отсортированную часть
   · Количество операций: 1 + 2 + 3 + ... + (n-1) = n(n-1)/2 ∈ O(n²)
2. Средний случай: O(n²)
   · В среднем каждый элемент нужно сдвигать через половину отсортированной части
   · Количество операций: примерно n²/4
3. Лучший случай: O(n)
   · Массив уже отсортирован
   · Для каждого элемента выполняется только одно сравнение
   · Внутренний цикл while не выполняется никогда

Пространственная сложность: O(1)

· Алгоритм сортирует "на месте"
· Использует только константное количество дополнительной памяти (key, i, j)
· Очень эффективен по использованию памяти

ДЕТАЛЬНЫЙ АНАЛИЗ ПОВЕДЕНИЯ:

Преимущества:

· Адаптивный - работает быстрее на частично отсортированных массивах
· Стабильный - сохраняет порядок одинаковых элементов
· Онлайн-алгоритм - может сортировать массив по мере поступления данных
· Эффективен для маленьких массивов - на практике часто используется как часть гибридных алгоритмов
· Простой в реализации - интуитивно понятный алгоритм

Недостатки:

· Медленный для больших массивов - квадратичная сложность делает его неэффективным для больших n
· Много операций сдвига - может быть медленным при работе с linked lists

Оптимизации на практике:

1. Бинарный поиск для вставки - можно использовать бинарный поиск для нахождения позиции вставки (уменьшает сравнения, но не сдвиги)
2. Шелл-сортировка - использует идею сортировки вставками с предварительным частичным упорядочиванием
3. Гибридные алгоритмы - часто используется в комбинации с быстрой сортировкой для маленьких подмассивов

Сравнение с предыдущими алгоритмами:

· Пузырьковая: O(n²) в лучшем случае vs Вставками: O(n) в лучшем случае
· Выбором: Всегда O(n²) vs Вставками: Адаптивный, O(n) для отсортированных данных
· Вставками обычно быстрее на практике из-за адаптивности

Практическое применение:

· В стандартных библиотеках для сортировки маленьких массивов
· В алгоритмах типа Timsort (гибрид слияния и вставок)
· В реальном времени для потоковых данных
· В embedded systems из-за малого потребления памяти

## 4. Сортировка слиянием
ПОДРОБНЫЙ АНАЛИЗ РАБОТЫ АЛГОРИТМА:

Принцип работы:
Сортировка слиянием использует стратегию "разделяй и властвуй". Алгоритм рекурсивно делит массив пополам до тех пор, пока не останутся массивы из одного элемента, затем сливает их в отсортированном порядке.

Пошаговый процесс выполнения на примере массива [38, 27, 43, 3, 9, 82, 10]:

Фаза разделения (Divide):
Уровень 0: [38, 27, 43, 3, 9, 82, 10]
Уровень 1: [38, 27, 43] и [3, 9, 82, 10]
Уровень 2: [38], [27, 43] и [3, 9], [82, 10]
Уровень 3: [38], [27], [43] и [3], [9], [82], [10]
Фаза слияния (Conquer):
Python

Слияние 1: [27, 43] ← [27] + [43] = [27, 43]
Слияние 2: [38] + [27, 43] = [27, 38, 43]
Слияние 3: [3, 9] ← [3] + [9] = [3, 9]
Слияние 4: [82, 10] ← [82] + [10] = [10, 82]
Слияние 5: [3, 9] + [10, 82] = [3, 9, 10, 82]
Слияние 6: [27, 38, 43] + [3, 9, 10, 82] = [3, 9, 10, 27, 38, 43, 82]
Детальный процесс слияния [27, 38, 43] и [3, 9, 10, 82]:

· Сравниваем 27 и 3: 3 < 27 → добавляем 3
· Сравниваем 27 и 9: 9 < 27 → добавляем 9
· Сравниваем 27 и 10: 10 < 27 → добавляем 10
· Сравниваем 27 и 82: 27 < 82 → добавляем 27
· Сравниваем 38 и 82: 38 < 82 → добавляем 38
· Сравниваем 43 и 82: 43 < 82 → добавляем 43
· Добавляем оставшийся 82

Результат: [3, 9, 10, 27, 38, 43, 82]

ОЦЕНКА ТРУДОЁМКОСТИ (НОТАЦИЯ BIG O):

Временная сложность:

1. Худший случай: O(n log n)
2. Средний случай: O(n log n)
3. Лучший случай: O(n log n)

Математическое обоснование:

· Глубина рекурсии: log₂n уровней (массив делится пополам каждый раз)
· Работа на каждом уровне: O(n) операций слияния
· Итого: O(n) × O(log n) = O(n log n)

Рекуррентное соотношение:
T(n) = 2T(n/2) + O(n)
По основной теореме: a = 2, b = 2, f(n) = O(n) → случай 2: T(n) = O(n log n)

Пространственная сложность: O(n)

· Требуется дополнительная память для временных массивов
· На каждом уровне рекурсии используется O(n) дополнительной памяти
· В наивной реализации может использоваться O(n log n) памяти из-за создания новых массивов

ДЕТАЛЬНЫЙ АНАЛИЗ ПОВЕДЕНИЯ:

Преимущества:

· Гарантированная производительность - всегда O(n log n) независимо от входных данных
· Стабильный алгоритм - сохраняет порядок одинаковых элементов
· Предсказуемое поведение - нет худшего случая деградации производительности
· Параллелизуемость - левая и правая части могут сортироваться параллельно
· Эффективен для внешней сортировки - хорошо работает с данными на диске

Недостатки:

· Высокая пространственная сложность - требует O(n) дополнительной памяти
· Не сортирует на месте - в классической реализации
· Низкая производительность на маленьких массивах - из-за накладных расходов на рекурсию
· Медленнее быстрой сортировки на практике - хотя имеет ту же асимптотику

Оптимизации:

1. Гибридный подход - использовать сортировку вставками для маленьких подмассивов (обычно n < 10-20)
2. Восходящая сортировка слиянием - итеративный подход без рекурсии
3. In-place слияние - сложные алгоритмы, позволяющие сливать без дополнительной памяти

Сравнение с предыдущими алгоритмами:

· Пузырьковая/Выбором/Вставками: O(n²) vs Слиянием: O(n log n) - экспоненциальное улучшение
· Вставками: O(n) в лучшем случае, но O(n²) в худшем vs Слиянием: Всегда O(n log n)
· Слиянием масштабируется значительно лучше для больших массивов

Практическое применение:

· В стандартных библиотеках (Java Collections.sort(), Python sorted())
· В базах данных для сортировки больших наборов данных
· В алгоритмах внешней сортировки (когда данные не помещаются в память)
· В MapReduce и распределенных системах
· В мультимедийных приложениях для обработки больших файлов

Особенности реализации в разных языках:

· Python: Возвращает новый массив, функциональный стиль
· Java: Может сортировать на месте или возвращать новый массив
· C++: std::stable_sort использует сортировку слиянием

## 5. Сортировка Шелла
Анализ работы алгоритма:

Сортировка Шелла представляет собой усовершенствованный вариант сортировки вставками. Алгоритм начинает с большого промежутка между сравниваемыми элементами и постепенно уменьшает этот промежуток. На каждом шаге массив становится более упорядоченным, что делает финальную сортировку с промежутком 1 очень эффективной.

Ключевые этапы:

· Начальный промежуток устанавливается в n/2
· Для каждого промежутка выполняется модифицированная сортировка вставками
· Промежуток последовательно уменьшается вдвое до достижения 1
· Финальный проход с промежутком 1 завершает сортировку

ОЦЕНКА ТРУДОЁМКОСТИ:

Временная сложность:

· Худший случай: O(n²) - зависит от выбора последовательности промежутков
· Средний случай: O(n log² n) - для оптимальных последовательностей
· Лучший случай: O(n log n) - для уже частично отсортированных массивов

Пространственная сложность: O(1)

· Алгоритм сортирует массив "на месте"
· Используется только константное количество дополнительной памяти

Обоснование сложности:
Эффективность алгоритма сильно зависит от выбранной последовательности промежутков. Для последовательности n/2, n/4, ..., 1 в худшем случае сохраняется квадратичная сложность, однако на практике алгоритм работает значительно лучше благодаря предварительному частичному упорядочиванию.

## 6. Быстрая сортировка
Анализ работы алгоритма:

Быстрая сортировка использует стратегию "разделяй и властвуй". Алгоритм выбирает опорный элемент и разбивает массив на две части: элементы меньше опорного и элементы больше опорного. Затем рекурсивно применяет тот же процесс к обеим частям.

Ключевые этапы:

1. Выбор опорного элемента - обычно последний элемент массива
2. Разбиение массива - перераспределение элементов относительно опорного
3. Рекурсивная сортировка - применение алгоритма к подмассивам

Пример выполнения для массива [10, 7, 8, 9, 1, 5]:

· Опорный элемент: 5
· После разбиения: [1, 5, 8, 9, 10, 7]
· Рекурсивная сортировка левой и правой частей

ОЦЕНКА ТРУДОЁМКОСТИ:
Временная сложность:

· Худший случай: O(n²) - когда опорный элемент всегда минимальный или максимальный
· Средний случай: O(n log n) - при случайном выборе опорного элемента
· Лучший случай: O(n log n) - когда опорный элемент делит массив пополам

Пространственная сложность: O(log n)

· Память используется для стека рекурсивных вызовов
· В худшем случае может достигать O(n)

Преимущества: Очень быстрый на практике, сортировка на месте
Недостатки: Неустойчивая сортировка, производительность зависит от выбора опорного элемента

## 7. Пирамидальная сортировка
Анализ работы алгоритма:

Пирамидальная сортировка использует структуру данных "двоичная куча" (binary heap). Алгоритм состоит из двух основных этапов: построение max-heap из входного массива и последовательное извлечение максимального элемента из кучи.

Ключевые этапы:

1. Построение max-heap - преобразование массива в структуру двоичной кучи, где каждый родительский элемент больше своих дочерних
2. Сортировка - максимальный элемент (корень) перемещается в конец массива, и куча перестраивается для оставшихся элементов

Пример выполнения для массива [12, 11, 13, 5, 6, 7]:
· Построение кучи: [13, 11, 12, 5, 6, 7]
· Извлечение максимального: 13 перемещается в конец
· Перестройка кучи для оставшихся элементов
· Процесс повторяется до полной сортировки

ОЦЕНКА ТРУДОЁМКОСТИ:

Временная сложность: O(n log n) во всех случаях (худшем, среднем, лучшем)

Пространственная сложность: O(1)

· Алгоритм сортирует массив "на месте"
· Используется только константное количество дополнительной памяти

Преимущества: Гарантированная производительность O(n log n), сортировка на месте
Недостатки: Неустойчивая сортировка, медленнее чем быстрая сортировка на практике

## 8. Последовательный поиск
Анализ работы алгоритма:

Последовательный поиск - это простейший алгоритм поиска, который проверяет каждый элемент массива по порядку до тех пор, пока не найдет искомый элемент или не достигнет конца массива.

Принцип работы:

· Алгоритм начинает с первого элемента массива
· Последовательно сравнивает каждый элемент с искомым значением
· Если элемент найден, возвращает его индекс
· Если достигнут конец массива и элемент не найден, возвращает -1

Пример выполнения для массива [3, 5, 2, 7, 9, 1, 4] и target = 7:

· Проверяем элемент 0: 3 ≠ 7
· Проверяем элемент 1: 5 ≠ 7
· Проверяем элемент 2: 2 ≠ 7
· Проверяем элемент 3: 7 = 7 → элемент найден на позиции 3

ОЦЕНКА ТРУДОЁМКОСТИ:

Временная сложность:

· Худший случай: O(n) - элемент находится в конце массива или отсутствует
· Средний случай: O(n) - элемент находится в середине массива
· Лучший случай: O(1) - элемент находится в начале массива

Пространственная сложность: O(1)

· Алгоритм использует только константное количество дополнительной памяти
· Не зависит от размера входного массива

Преимущества: Простота реализации, работает с неотсортированными массивами
Недостатки: Медленный для больших массивов, неэффективен при частых поисках

## 9. Бинарный поиск
Анализ работы алгоритма:

Бинарный поиск - это эффективный алгоритм для нахождения элемента в отсортированном массиве. Алгоритм работает по принципу "разделяй и властвуй", постоянно уменьшая область поиска вдвое.

Принцип работы:

· Алгоритм начинает с всего массива
· На каждой итерации сравнивает средний элемент с искомым значением
· Если средний элемент равен целевому - поиск завершен
· Если целевой элемент меньше среднего - поиск продолжается в левой половине
· Если целевой элемент больше среднего - поиск продолжается в правой половине
· Процесс повторяется до нахождения элемента или исчерпания области поиска

Пример выполнения для массива [1, 3, 5, 7, 9, 11, 13, 15, 17, 19] и target = 7:

· Итерация 1: left=0, right=9, mid=4 → array[4]=9 > 7 → right=3
· Итерация 2: left=0, right=3, mid=1 → array[1]=3 < 7 → left=2
· Итерация 3: left=2, right=3, mid=2 → array[2]=5 < 7 → left=3
· Итерация 4: left=3, right=3, mid=3 → array[3]=7 = 7 → элемент найден

ОЦЕНКА ТРУДОЁМКОСТИ:

Временная сложность: O(log n)

· Худший случай: O(log n) - элемент находится на краю или отсутствует
· Средний случай: O(log n) - элемент находится в произвольной позиции
· Лучший случай: O(1) - элемент находится точно в середине массива

Пространственная сложность: O(1)

· Итеративная версия использует константную память
· Рекурсивная версия имеет O(log n) из-за стека вызовов

Преимущества: Очень быстрый для больших отсортированных массивов
Недостатки: Требует предварительной сортировки массива, не работает с несортированными данными

Важное замечание: Формула mid = left + (right - left) / 2 защищает от переполнения, которое может возникнуть при использовании mid = (left + right) / 2 для очень больших массивов.

## 10. Интерполирующий поиск
Анализ работы алгоритма:
Интерполяционный поиск - это улучшенная версия бинарного поиска, которая работает лучше на равномерно распределенных отсортированных данных. Вместо деления массива пополам, алгоритм вычисляет вероятную позицию элемента на основе его значения.

Принцип работы:

· Алгоритм использует интерполяционную формулу для предсказания позиции элемента
· Формула основана на предположении о линейном распределении элементов
· На каждой итерации область поиска сужается в зависимости от сравнения
· Процесс повторяется до нахождения элемента или исчерпания области поиска

Интерполяционная формула:
pos = low + ((target - arr[low]) * (high - low)) / (arr[high] - arr[low])

Пример выполнения для массива [10, 12, 13, 16, 18, 19, 20, 21, 22, 23, 24, 33, 35, 42, 47] и target = 18:

· low=0, high=14, arr[low]=10, arr[high]=47
· pos = 0 + ((18-10)(14-0))/(47-10) = 0 + (814)/37 ≈ 3.02 → pos=3
· arr[3]=16 < 18 → low=4
· Новый диапазон: low=4, high=14 → продолжаем поиск

ОЦЕНКА ТРУДОЁМКОСТИ:

Временная сложность:

· Лучший случай: O(log log n) - для равномерно распределенных данных
· Средний случай: O(log log n) - при хорошем распределении
· Худший случай: O(n) - при неравномерном распределении (например, экспоненциальном)

Пространственная сложность: O(1)

· Итеративная версия использует константную память
· Рекурсивная версия имеет O(log n) из-за стека вызовов

Преимущества: Очень быстрый для равномерно распределенных данных, превосходит бинарный поиск в лучшем случае
Недостатки: Требует равномерного распределения данных, сложнее в реализации, может быть медленнее бинарного поиска при плохом распределении

Области применения: Базы данных, телефонные справочники, равномерно распределенные числовые данные

## 11. Фибоначчи поиск





















